{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec274175",
   "metadata": {},
   "source": [
    "# Topic Canonicalization Workflow\n",
    "Consolidate NOVEL topics into the registry using embeddings + LLM review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deef9ab",
   "metadata": {},
   "source": [
    "## Load Registry and Novel Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfd8cd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 32 registry topics (version 001, created 2025-10-27T00:00:00+05:30)\n",
      "Found 91 unique novel candidates\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(REGISTRY_PATH) as f:\n",
    "    registry = json.load(f)\n",
    "\n",
    "registry_version = registry.get('version', 'unknown')\n",
    "registry_created = registry.get('created_at')\n",
    "existing_topics = registry['topics']\n",
    "print(f\"Loaded {len(existing_topics)} registry topics (version {registry_version}, created {registry_created})\")\n",
    "\n",
    "novel_frames = []\n",
    "for path in sorted((DATA_DIR / 'daily_labels').glob('labels_*.parquet')):\n",
    "    df = pl.read_parquet(path)\n",
    "    novel_subset = df.filter((pl.col('topic_id') == 'NOVEL') & pl.col('novel_label').is_not_null())\n",
    "    if len(novel_subset) > 0:\n",
    "        novel_frames.append(novel_subset)\n",
    "\n",
    "if not novel_frames:\n",
    "    raise ValueError('No NOVEL topics found to canonicalize.')\n",
    "\n",
    "novel_df = pl.concat(novel_frames).with_columns([\n",
    "    pl.col('created_at').dt.convert_time_zone('Asia/Kolkata'),\n",
    "]).unique(subset=['novel_label'])\n",
    "print(f'Found {len(novel_df)} unique novel candidates')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c06b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "MODEL_ID = os.getenv(\"KAGGLE_MODEL_ID\", \"Qwen/Qwen2.5-3B-Instruct\")\n",
    "MAX_NEW_TOKENS = int(os.getenv(\"KAGGLE_MAX_NEW_TOKENS\", \"180\"))\n",
    "\n",
    "print(f\"Loading local model {MODEL_ID}…\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map=\"auto\",\n",
    "    load_in_4bit=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "MODEL = MODEL_ID\n",
    "print(f\"✓ Loaded local HF model {MODEL_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976857aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import nullcontext\n",
    "\n",
    "class TransformersLLMClient:\n",
    "    def __init__(self, model, tokenizer, max_new_tokens=MAX_NEW_TOKENS):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_new_tokens = max_new_tokens\n",
    "\n",
    "    def complete(self, system_prompt, user_prompt, temperature=0.2, response_format='json', use_cache=True):\n",
    "        prompt = f\"{system_prompt}\n",
    "\n",
    "User: {user_prompt}\n",
    "\n",
    "Assistant:\"\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
    "\n",
    "        autocast_ctx = torch.cuda.amp.autocast() if torch.cuda.is_available() else nullcontext()\n",
    "        with torch.inference_mode():\n",
    "            with autocast_ctx:\n",
    "                outputs = self.model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=self.max_new_tokens,\n",
    "                    temperature=temperature,\n",
    "                    do_sample=temperature > 0,\n",
    "                    pad_token_id=self.tokenizer.eos_token_id,\n",
    "                )\n",
    "\n",
    "        text = self.tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"Assistant:\")[-1].strip()\n",
    "        if response_format == 'json':\n",
    "            try:\n",
    "                return json.loads(text)\n",
    "            except json.JSONDecodeError:\n",
    "                return {\"error\": text}\n",
    "        return text\n",
    "\n",
    "    def batch_complete(self, prompts, batch_size=4):\n",
    "        results = []\n",
    "        for item in prompts:\n",
    "            results.append(self.complete(\n",
    "                item['system_prompt'],\n",
    "                item['user_prompt'],\n",
    "                item.get('temperature', 0.3),\n",
    "                item.get('response_format', 'json')\n",
    "            ))\n",
    "        return results\n",
    "\n",
    "llm = TransformersLLMClient(model, tokenizer)\n",
    "print(\"✓ Initialized local transformers client\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e09b18",
   "metadata": {},
   "source": [
    "## Summarize Novel Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "399bf794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Aggregated 91 novel topic candidates\n",
      "  Saved summary to ../data/novel_topic_summary.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>novel_label</th><th>review_count</th><th>sample_rationale</th><th>first_seen</th><th>last_seen</th></tr><tr><td>str</td><td>u32</td><td>str</td><td>datetime[μs, Asia/Kolkata]</td><td>datetime[μs, Asia/Kolkata]</td></tr></thead><tbody><tr><td>&quot;Unidentifiable Issue&quot;</td><td>1</td><td>&quot;The review text &#x27;thinkyou&#x27; doe…</td><td>2025-09-28 07:17:34 IST</td><td>2025-09-28 07:17:34 IST</td></tr><tr><td>&quot;Unidentifiable Review&quot;</td><td>1</td><td>&quot;The review does not provide an…</td><td>2025-09-29 17:14:33 IST</td><td>2025-09-29 17:14:33 IST</td></tr><tr><td>&quot;Emoticon in Review&quot;</td><td>1</td><td>&quot;The review contains emoticons …</td><td>2025-09-28 17:57:28 IST</td><td>2025-09-28 17:57:28 IST</td></tr><tr><td>&quot;Emoji-only Review&quot;</td><td>1</td><td>&quot;The review consists only of em…</td><td>2025-09-28 12:47:38 IST</td><td>2025-09-28 12:47:38 IST</td></tr><tr><td>&quot;Location Issue&quot;</td><td>1</td><td>&quot;The review mentions issues spe…</td><td>2025-09-28 15:06:53 IST</td><td>2025-09-28 15:06:53 IST</td></tr><tr><td>&quot;Facility Issue&quot;</td><td>1</td><td>&quot;The review mentions a lack of …</td><td>2025-09-28 07:15:35 IST</td><td>2025-09-28 07:15:35 IST</td></tr><tr><td>&quot;Negative Sentiment&quot;</td><td>1</td><td>&quot;The review expresses a negativ…</td><td>2025-09-28 17:51:28 IST</td><td>2025-09-28 17:51:28 IST</td></tr><tr><td>&quot;Unrecognized Issue&quot;</td><td>1</td><td>&quot;The review text is not related…</td><td>2025-09-28 20:33:13 IST</td><td>2025-09-28 20:33:13 IST</td></tr><tr><td>&quot;Cheating Experience&quot;</td><td>1</td><td>&quot;The review mentions &#x27;cheaters,…</td><td>2025-09-28 15:30:24 IST</td><td>2025-09-28 15:30:24 IST</td></tr><tr><td>&quot;Short Thank You Message&quot;</td><td>1</td><td>&quot;The review is a short thank yo…</td><td>2025-09-29 17:52:35 IST</td><td>2025-09-29 17:52:35 IST</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 5)\n",
       "┌──────────────────────┬──────────────┬──────────────────────┬───────────────┬─────────────────────┐\n",
       "│ novel_label          ┆ review_count ┆ sample_rationale     ┆ first_seen    ┆ last_seen           │\n",
       "│ ---                  ┆ ---          ┆ ---                  ┆ ---           ┆ ---                 │\n",
       "│ str                  ┆ u32          ┆ str                  ┆ datetime[μs,  ┆ datetime[μs,        │\n",
       "│                      ┆              ┆                      ┆ Asia/Kolkata] ┆ Asia/Kolkata]       │\n",
       "╞══════════════════════╪══════════════╪══════════════════════╪═══════════════╪═════════════════════╡\n",
       "│ Unidentifiable Issue ┆ 1            ┆ The review text      ┆ 2025-09-28    ┆ 2025-09-28 07:17:34 │\n",
       "│                      ┆              ┆ 'thinkyou' doe…      ┆ 07:17:34 IST  ┆ IST                 │\n",
       "│ Unidentifiable       ┆ 1            ┆ The review does not  ┆ 2025-09-29    ┆ 2025-09-29 17:14:33 │\n",
       "│ Review               ┆              ┆ provide an…          ┆ 17:14:33 IST  ┆ IST                 │\n",
       "│ Emoticon in Review   ┆ 1            ┆ The review contains  ┆ 2025-09-28    ┆ 2025-09-28 17:57:28 │\n",
       "│                      ┆              ┆ emoticons …          ┆ 17:57:28 IST  ┆ IST                 │\n",
       "│ Emoji-only Review    ┆ 1            ┆ The review consists  ┆ 2025-09-28    ┆ 2025-09-28 12:47:38 │\n",
       "│                      ┆              ┆ only of em…          ┆ 12:47:38 IST  ┆ IST                 │\n",
       "│ Location Issue       ┆ 1            ┆ The review mentions  ┆ 2025-09-28    ┆ 2025-09-28 15:06:53 │\n",
       "│                      ┆              ┆ issues spe…          ┆ 15:06:53 IST  ┆ IST                 │\n",
       "│ Facility Issue       ┆ 1            ┆ The review mentions  ┆ 2025-09-28    ┆ 2025-09-28 07:15:35 │\n",
       "│                      ┆              ┆ a lack of …          ┆ 07:15:35 IST  ┆ IST                 │\n",
       "│ Negative Sentiment   ┆ 1            ┆ The review expresses ┆ 2025-09-28    ┆ 2025-09-28 17:51:28 │\n",
       "│                      ┆              ┆ a negativ…           ┆ 17:51:28 IST  ┆ IST                 │\n",
       "│ Unrecognized Issue   ┆ 1            ┆ The review text is   ┆ 2025-09-28    ┆ 2025-09-28 20:33:13 │\n",
       "│                      ┆              ┆ not related…         ┆ 20:33:13 IST  ┆ IST                 │\n",
       "│ Cheating Experience  ┆ 1            ┆ The review mentions  ┆ 2025-09-28    ┆ 2025-09-28 15:30:24 │\n",
       "│                      ┆              ┆ 'cheaters,…          ┆ 15:30:24 IST  ┆ IST                 │\n",
       "│ Short Thank You      ┆ 1            ┆ The review is a      ┆ 2025-09-29    ┆ 2025-09-29 17:52:35 │\n",
       "│ Message              ┆              ┆ short thank yo…      ┆ 17:52:35 IST  ┆ IST                 │\n",
       "└──────────────────────┴──────────────┴──────────────────────┴───────────────┴─────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Summarize novel topics by frequency and recency\n",
    "novel_summary = novel_df.group_by('novel_label').agg([\n",
    "    pl.len().alias('review_count'),\n",
    "    pl.first('novel_rationale').alias('sample_rationale'),\n",
    "    pl.min('created_at').alias('first_seen'),\n",
    "    pl.max('created_at').alias('last_seen'),\n",
    "]).sort('review_count', descending=True)\n",
    "\n",
    "print(f\"✓ Aggregated {len(novel_summary)} novel topic candidates\")\n",
    "summary_path = DATA_DIR / 'novel_topic_summary.parquet'\n",
    "novel_summary.write_parquet(summary_path)\n",
    "print(f\"  Saved summary to {summary_path}\")\n",
    "\n",
    "try:\n",
    "    display(novel_summary.head(10))\n",
    "except NameError:\n",
    "    print(novel_summary.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e2e7bb",
   "metadata": {},
   "source": [
    "## Compute Embeddings and Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c36f8b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53298085d0ac47378c5c021d198eaf44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c50fb65318414510b00c194ab0ac4787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f111b2ae651498aa814a4d019c4bf22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e256e7fb22f4ad1991a32f446a9756b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1221c16df2d4358875fefea2d9d8f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6498f11aab5742fd8b7f331616d0622b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e66a24c33614e80ab4e2fdbfe370968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb021f276f4f423691bdb4af2f831d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71a426c1b59457dae8cd321a967d108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10e739c2b1e445d94aee88c904977a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f334d50ddbe4dfe9c715fe5dcd1ccf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded embedding model all-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d400c8efa84d3d81b6a9984ba7a6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b7845dcee54642b61204c28c711ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Candidate matches computed (91 rows)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>novel_label</th><th>novel_rationale</th><th>first_seen</th><th>best_topic_id</th><th>best_topic_name</th><th>similarity</th></tr><tr><td>str</td><td>str</td><td>datetime[μs, Asia/Kolkata]</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Late delivery due to time&quot;</td><td>&quot;The review mentions that the o…</td><td>2025-09-28 06:58:59 IST</td><td>&quot;LATE_DELIVERY&quot;</td><td>&quot;Late Delivery&quot;</td><td>0.737176</td></tr><tr><td>&quot;Negative Generic&quot;</td><td>&quot;The review provides a very bri…</td><td>2025-09-28 15:55:05 IST</td><td>&quot;NEGATIVE_GENERIC&quot;</td><td>&quot;Negative Generic&quot;</td><td>0.710988</td></tr><tr><td>&quot;Generic Negative Feedback&quot;</td><td>&quot;The review provides very minim…</td><td>2025-09-28 14:19:36 IST</td><td>&quot;NEGATIVE_GENERIC&quot;</td><td>&quot;Negative Generic&quot;</td><td>0.710497</td></tr><tr><td>&quot;General Positive Feedback&quot;</td><td>&quot;The review is very brief and d…</td><td>2025-09-28 08:39:22 IST</td><td>&quot;POSITIVE_EXPERIENCE&quot;</td><td>&quot;Positive Experience&quot;</td><td>0.658837</td></tr><tr><td>&quot;Positive Feedback&quot;</td><td>&quot;The review is a generic positi…</td><td>2025-09-28 16:58:44 IST</td><td>&quot;POSITIVE_EXPERIENCE&quot;</td><td>&quot;Positive Experience&quot;</td><td>0.651657</td></tr><tr><td>&quot;App Feedback&quot;</td><td>&quot;The review provides positive f…</td><td>2025-09-28 10:41:48 IST</td><td>&quot;GREAT_APP&quot;</td><td>&quot;Great App&quot;</td><td>0.640818</td></tr><tr><td>&quot;Generic Positive Feedback&quot;</td><td>&quot;The review is very brief and d…</td><td>2025-09-28 00:43:13 IST</td><td>&quot;POSITIVE_EXPERIENCE&quot;</td><td>&quot;Positive Experience&quot;</td><td>0.633143</td></tr><tr><td>&quot;General Negative Feedback&quot;</td><td>&quot;The review provides a very bri…</td><td>2025-09-28 19:13:15 IST</td><td>&quot;POSITIVE_EXPERIENCE&quot;</td><td>&quot;Positive Experience&quot;</td><td>0.598888</td></tr><tr><td>&quot;Service Improvement Suggestion&quot;</td><td>&quot;The review suggests a general …</td><td>2025-09-28 14:05:50 IST</td><td>&quot;POSITIVE_EXPERIENCE&quot;</td><td>&quot;Positive Experience&quot;</td><td>0.58318</td></tr><tr><td>&quot;Positive Cost Experience&quot;</td><td>&quot;The review highlights a positi…</td><td>2025-09-28 06:45:15 IST</td><td>&quot;POSITIVE_EXPERIENCE&quot;</td><td>&quot;Positive Experience&quot;</td><td>0.569358</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 6)\n",
       "┌─────────────────┬────────────────┬────────────────┬────────────────┬────────────────┬────────────┐\n",
       "│ novel_label     ┆ novel_rational ┆ first_seen     ┆ best_topic_id  ┆ best_topic_nam ┆ similarity │\n",
       "│ ---             ┆ e              ┆ ---            ┆ ---            ┆ e              ┆ ---        │\n",
       "│ str             ┆ ---            ┆ datetime[μs,   ┆ str            ┆ ---            ┆ f64        │\n",
       "│                 ┆ str            ┆ Asia/Kolkata]  ┆                ┆ str            ┆            │\n",
       "╞═════════════════╪════════════════╪════════════════╪════════════════╪════════════════╪════════════╡\n",
       "│ Late delivery   ┆ The review     ┆ 2025-09-28     ┆ LATE_DELIVERY  ┆ Late Delivery  ┆ 0.737176   │\n",
       "│ due to time     ┆ mentions that  ┆ 06:58:59 IST   ┆                ┆                ┆            │\n",
       "│                 ┆ the o…         ┆                ┆                ┆                ┆            │\n",
       "│ Negative        ┆ The review     ┆ 2025-09-28     ┆ NEGATIVE_GENER ┆ Negative       ┆ 0.710988   │\n",
       "│ Generic         ┆ provides a     ┆ 15:55:05 IST   ┆ IC             ┆ Generic        ┆            │\n",
       "│                 ┆ very bri…      ┆                ┆                ┆                ┆            │\n",
       "│ Generic         ┆ The review     ┆ 2025-09-28     ┆ NEGATIVE_GENER ┆ Negative       ┆ 0.710497   │\n",
       "│ Negative        ┆ provides very  ┆ 14:19:36 IST   ┆ IC             ┆ Generic        ┆            │\n",
       "│ Feedback        ┆ minim…         ┆                ┆                ┆                ┆            │\n",
       "│ General         ┆ The review is  ┆ 2025-09-28     ┆ POSITIVE_EXPER ┆ Positive       ┆ 0.658837   │\n",
       "│ Positive        ┆ very brief and ┆ 08:39:22 IST   ┆ IENCE          ┆ Experience     ┆            │\n",
       "│ Feedback        ┆ d…             ┆                ┆                ┆                ┆            │\n",
       "│ Positive        ┆ The review is  ┆ 2025-09-28     ┆ POSITIVE_EXPER ┆ Positive       ┆ 0.651657   │\n",
       "│ Feedback        ┆ a generic      ┆ 16:58:44 IST   ┆ IENCE          ┆ Experience     ┆            │\n",
       "│                 ┆ positi…        ┆                ┆                ┆                ┆            │\n",
       "│ App Feedback    ┆ The review     ┆ 2025-09-28     ┆ GREAT_APP      ┆ Great App      ┆ 0.640818   │\n",
       "│                 ┆ provides       ┆ 10:41:48 IST   ┆                ┆                ┆            │\n",
       "│                 ┆ positive f…    ┆                ┆                ┆                ┆            │\n",
       "│ Generic         ┆ The review is  ┆ 2025-09-28     ┆ POSITIVE_EXPER ┆ Positive       ┆ 0.633143   │\n",
       "│ Positive        ┆ very brief and ┆ 00:43:13 IST   ┆ IENCE          ┆ Experience     ┆            │\n",
       "│ Feedback        ┆ d…             ┆                ┆                ┆                ┆            │\n",
       "│ General         ┆ The review     ┆ 2025-09-28     ┆ POSITIVE_EXPER ┆ Positive       ┆ 0.598888   │\n",
       "│ Negative        ┆ provides a     ┆ 19:13:15 IST   ┆ IENCE          ┆ Experience     ┆            │\n",
       "│ Feedback        ┆ very bri…      ┆                ┆                ┆                ┆            │\n",
       "│ Service         ┆ The review     ┆ 2025-09-28     ┆ POSITIVE_EXPER ┆ Positive       ┆ 0.58318    │\n",
       "│ Improvement     ┆ suggests a     ┆ 14:05:50 IST   ┆ IENCE          ┆ Experience     ┆            │\n",
       "│ Suggestion      ┆ general …      ┆                ┆                ┆                ┆            │\n",
       "│ Positive Cost   ┆ The review     ┆ 2025-09-28     ┆ POSITIVE_EXPER ┆ Positive       ┆ 0.569358   │\n",
       "│ Experience      ┆ highlights a   ┆ 06:45:15 IST   ┆ IENCE          ┆ Experience     ┆            │\n",
       "│                 ┆ positi…        ┆                ┆                ┆                ┆            │\n",
       "└─────────────────┴────────────────┴────────────────┴────────────────┴────────────────┴────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "print(f\"✓ Loaded embedding model {MODEL_NAME}\")\n",
    "\n",
    "registry_corpus = [topic['name'] + ' ' + topic['definition'] for topic in existing_topics]\n",
    "registry_matrix = model.encode(registry_corpus, show_progress_bar=True)\n",
    "\n",
    "novel_texts = [\n",
    "    f\"{row['novel_label']} :: {row['novel_rationale']}\" if row['novel_rationale'] else row['novel_label']\n",
    "    for row in novel_df.iter_rows(named=True)\n",
    "]\n",
    "novel_matrix = model.encode(novel_texts, show_progress_bar=True)\n",
    "\n",
    "similarities = cosine_similarity(novel_matrix, registry_matrix)\n",
    "\n",
    "candidate_matches = []\n",
    "for idx, novel_row in enumerate(novel_df.iter_rows(named=True)):\n",
    "    best_idx = similarities[idx].argmax()\n",
    "    score = float(similarities[idx][best_idx])\n",
    "    registry_topic = existing_topics[int(best_idx)]\n",
    "    candidate_matches.append({\n",
    "        'novel_label': novel_row['novel_label'],\n",
    "        'novel_rationale': novel_row['novel_rationale'],\n",
    "        'first_seen': novel_row['created_at'],\n",
    "        'best_topic_id': registry_topic['id'],\n",
    "        'best_topic_name': registry_topic['name'],\n",
    "        'similarity': score\n",
    "    })\n",
    "\n",
    "candidate_df = pl.DataFrame(candidate_matches).sort('similarity', descending=True)\n",
    "print(f\"✓ Candidate matches computed ({len(candidate_df)} rows)\")\n",
    "try:\n",
    "    display(candidate_df.head(10))\n",
    "except NameError:\n",
    "    print(candidate_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be90ad22",
   "metadata": {},
   "source": [
    "## Resolve Ambiguous Candidates with LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d768e90",
   "metadata": {},
   "source": [
    "## Write Registry Update Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4e90eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Proposed updates written to ../data/registry_updates.json\n",
      "  Preview CSV written to ../data/registry_updates_preview.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "updates = []\n",
    "timestamp = datetime.utcnow().isoformat() + 'Z'\n",
    "for row in actions_df.iter_rows(named=True):\n",
    "    updates.append({\n",
    "        'timestamp': timestamp,\n",
    "        'novel_label': row['novel_label'],\n",
    "        'target_topic_id': row['best_topic_id'],\n",
    "        'target_topic_name': row['best_topic_name'],\n",
    "        'similarity': row['similarity'],\n",
    "        'action': row['action'],\n",
    "        'notes': row.get('notes'),\n",
    "        'llm_label': row.get('llm_label'),\n",
    "        'first_seen': row.get('first_seen'),\n",
    "    })\n",
    "\n",
    "updates_path = DATA_DIR / 'registry_updates.json'\n",
    "with updates_path.open('w') as f:\n",
    "    json.dump(updates, f, indent=2, default=str)\n",
    "print(f'✓ Proposed updates written to {updates_path}')\n",
    "\n",
    "review_path = DATA_DIR / 'registry_updates_preview.csv'\n",
    "actions_df.write_csv(review_path)\n",
    "print(f'  Preview CSV written to {review_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422e531e",
   "metadata": {},
   "source": [
    "## Manual Follow-up\n",
    "- Review `data/registry_updates.json`\n",
    "- Apply merges/new topics in `registry/topic_registry.json`\n",
    "- Re-run topic routing if registry changes materially\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (amazon)",
   "language": "python",
   "name": "amazon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
