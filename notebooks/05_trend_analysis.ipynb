{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30-Day Trend Analysis\n",
    "\n",
    "This notebook generates rolling 30-day trend tables with DuckDB pivots and HTML export.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Setup complete\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import polars as pl\n",
    "import duckdb\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "\n",
    "# Set up paths\n",
    "DATA_DIR = Path(\"../data\")\n",
    "LABELS_FILE = DATA_DIR / \"labels_initial.parquet\"\n",
    "REGISTRY_FILE = Path(\"../registry/topic_registry.json\")\n",
    "OUTPUT_DIR = Path(\"../output\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"‚úì Setup complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded 27,381 topic assignments\n",
      "‚úì Loaded 32 topic definitions (registry v001)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data\n",
    "labels_df = pl.read_parquet(LABELS_FILE)\n",
    "if labels_df.is_empty():\n",
    "    raise ValueError(f\"No topic assignments found in {LABELS_FILE}\")\n",
    "print(f\"‚úì Loaded {len(labels_df):,} topic assignments\")\n",
    "\n",
    "required_columns = {'topic_id', 'created_at'}\n",
    "missing = required_columns - set(labels_df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"labels parquet missing required columns: {missing}\")\n",
    "\n",
    "# Load registry for topic names\n",
    "with open(REGISTRY_FILE) as f:\n",
    "    registry = json.load(f)\n",
    "\n",
    "registry_version = registry.get('version', 'unknown')\n",
    "topic_map = {t['id']: t['name'] for t in registry['topics']}\n",
    "print(f\"‚úì Loaded {len(topic_map)} topic definitions (registry v{registry_version})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate 30-Day Pivot Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Date range: 2025-09-28 to 2025-10-28\n",
      "‚úì Filtered to 27,381 assignments in date range\n",
      "  Unique topics in window: 33\n",
      "  Unique dates in window: 28\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate date range (last 31 days)\n",
    "end_date = datetime.now().date()\n",
    "start_date = end_date - timedelta(days=30)\n",
    "\n",
    "print(f\"üìÖ Date range: {start_date} to {end_date}\")\n",
    "\n",
    "# Convert created_at to date\n",
    "labels_dated = labels_df.with_columns([\n",
    "    pl.col(\"created_at\").dt.date().alias(\"date\")\n",
    "])\n",
    "\n",
    "# Filter to date range\n",
    "labels_filtered = labels_dated.filter(\n",
    "    (pl.col(\"date\") >= start_date) & (pl.col(\"date\") <= end_date)\n",
    ")\n",
    "\n",
    "if labels_filtered.is_empty():\n",
    "    raise ValueError('No topic assignments found in the last 30 days. Check routing outputs or adjust the window.')\n",
    "\n",
    "print(f\"‚úì Filtered to {len(labels_filtered):,} assignments in date range\")\n",
    "print(f\"  Unique topics in window: {labels_filtered['topic_id'].n_unique()}\")\n",
    "print(f\"  Unique dates in window: {labels_filtered['date'].n_unique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Created pivot table: 33 topics √ó 28 dates\n"
     ]
    }
   ],
   "source": [
    "# Use DuckDB for efficient pivot\n",
    "conn = duckdb.connect()\n",
    "\n",
    "# Create temp view\n",
    "conn.register('labels', labels_filtered)\n",
    "\n",
    "# Get unique dates\n",
    "dates = labels_filtered[\"date\"].unique().sort().to_list()\n",
    "if not dates:\n",
    "    raise ValueError('No dates available after filtering. Ensure labels contain recent data.')\n",
    "\n",
    "date_strs = [d.strftime(\"%Y-%m-%d\") for d in dates]\n",
    "\n",
    "# Generate pivot query\n",
    "sql = \"\"\"\n",
    "SELECT \n",
    "    topic_id,\n",
    "\"\"\"\n",
    "for date_str in date_strs:\n",
    "    sql += f'''    SUM(CASE WHEN date = DATE '{date_str}' THEN 1 ELSE 0 END) AS \"{date_str}\",\\n'''\n",
    "\n",
    "sql = sql.rstrip(\",\\n\") + \"\"\"\n",
    "FROM labels\n",
    "WHERE date IS NOT NULL\n",
    "GROUP BY topic_id\n",
    "ORDER BY topic_id\n",
    "\"\"\"\n",
    "\n",
    "trend_df = conn.execute(sql).df()\n",
    "if trend_df.empty:\n",
    "    raise ValueError('Pivot table returned no data. Verify topic assignments for the selected window.')\n",
    "\n",
    "print(f\"‚úì Created pivot table: {len(trend_df)} topics √ó {len(date_strs)} dates\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute 7-Day Change Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Calculated 7-day change percentages across 7 recent days\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate 7-day change percentage for each topic\n",
    "trend_pd = trend_df.set_index('topic_id')\n",
    "\n",
    "if len(date_strs) >= 14:\n",
    "    recent_window = date_strs[-7:]\n",
    "    prev_window = date_strs[-14:-7]\n",
    "    recent_7_days = trend_pd[recent_window].sum(axis=1)\n",
    "    prev_7_days = trend_pd[prev_window].sum(axis=1)\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        change_pct = ((recent_7_days - prev_7_days) / prev_7_days.replace(0, np.nan) * 100)\n",
    "    change_pct = change_pct.fillna(0).astype(float)\n",
    "\n",
    "    trend_df['7d_change_pct'] = change_pct.values\n",
    "    trend_df['recent_7d_total'] = recent_7_days.values\n",
    "    trend_df['prev_7d_total'] = prev_7_days.values\n",
    "\n",
    "    print(f\"‚úì Calculated 7-day change percentages across {len(recent_window)} recent days\")\n",
    "else:\n",
    "    trend_df['7d_change_pct'] = 0.0\n",
    "    trend_df['recent_7d_total'] = 0\n",
    "    trend_df['prev_7d_total'] = 0\n",
    "    print('‚ö† Not enough dates for 7-day change calculation; filled with zeros')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sparklines (Unicode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Generated sparklines\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate sparklines using Unicode block characters\n",
    "def generate_sparkline(values):\n",
    "    \"\"\"Generate Unicode sparkline from list of values\"\"\"\n",
    "    if not values or all(v == 0 for v in values):\n",
    "        return \"‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\"\n",
    "\n",
    "    min_val, max_val = min(values), max(values)\n",
    "    if max_val == min_val:\n",
    "        return \"‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ\"\n",
    "\n",
    "    normalized = [(v - min_val) / (max_val - min_val) * 7 for v in values]\n",
    "    blocks = \"‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\"\n",
    "\n",
    "    sparkline = \"\".join([blocks[int(min(7, round(v)))] for v in normalized])\n",
    "    return sparkline\n",
    "\n",
    "# Add sparklines\n",
    "sparklines = []\n",
    "for _, row in trend_pd.iterrows():\n",
    "    values = [row[date_str] for date_str in date_strs]\n",
    "    sparklines.append(generate_sparkline(values))\n",
    "\n",
    "trend_df['sparkline'] = sparklines\n",
    "trend_df['latest_date'] = date_strs[-1]\n",
    "trend_df['latest_count'] = trend_df[date_strs[-1]]\n",
    "print(\"‚úì Generated sparklines\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to CSV and HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Saved CSV to ../output/topics_trend_2025-10-28.csv\n",
      "  Debug CSV saved to ../output/topics_trend_2025-10-28_debug.csv\n",
      "‚úì Saved HTML to ../output/topics_trend_2025-10-28.html\n",
      "\n",
      "üìä Top 10 Topics (by recent activity):\n",
      "  Positive Experience: 228.0 reviews (-5.4%)\n",
      "  NOVEL: 87.0 reviews (+5.0%)\n",
      "  Negative Generic: 86.0 reviews (-6.2%)\n",
      "  Very Good Service: 52.0 reviews (-7.3%)\n",
      "  Late Delivery: 43.0 reviews (-10.2%)\n",
      "  Good Quality Food: 37.0 reviews (-3.8%)\n",
      "  Great App: 35.0 reviews (-9.5%)\n",
      "  Unprofessional Behavior: 33.0 reviews (-14.1%)\n",
      "  High Fees: 29.0 reviews (-18.5%)\n",
      "  Bot Only No Human Support: 27.0 reviews (-12.7%)\n"
     ]
    }
   ],
   "source": [
    "# Save CSV\n",
    "csv_file = OUTPUT_DIR / f\"topics_trend_{end_date}.csv\"\n",
    "trend_df.to_csv(csv_file, index=False)\n",
    "print(f\"‚úì Saved CSV to {csv_file}\")\n",
    "\n",
    "# Save enriched CSV for debugging\n",
    "csv_debug_file = OUTPUT_DIR / f\"topics_trend_{end_date}_debug.csv\"\n",
    "debug_columns = ['topic_id', 'latest_count', 'recent_7d_total', 'prev_7d_total', '7d_change_pct', 'sparkline'] + date_strs\n",
    "debug_df = trend_df[debug_columns]\n",
    "debug_df.to_csv(csv_debug_file, index=False)\n",
    "print(f\"  Debug CSV saved to {csv_debug_file}\")\n",
    "\n",
    "# Generate HTML\n",
    "html = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Topic Trends - {end_date}</title>\n",
    "    <style>\n",
    "        body {{ font-family: Arial, sans-serif; margin: 20px; }}\n",
    "        table {{ border-collapse: collapse; width: 100%; }}\n",
    "        th, td {{ padding: 8px; text-align: left; border-bottom: 1px solid #ddd; }}\n",
    "        th {{ background-color: #f2f2f2; }}\n",
    "        .positive {{ color: green; }}\n",
    "        .negative {{ color: red; }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Topic Trends: Last 30 Days</h1>\n",
    "    <p>Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
    "    <table>\n",
    "        <tr>\n",
    "            <th>Topic ID</th>\n",
    "            <th>Topic Name</th>\n",
    "            <th>Trend</th>\n",
    "            <th>7d Œî%</th>\n",
    "            <th>Recent Total</th>\n",
    "            <th>Prev Total</th>\n",
    "\"\"\"\n",
    "\n",
    "for date_str in date_strs[-7:]:  # Show last 7 dates\n",
    "    html += f\"            <th>{date_str}</th>\\n\"\n",
    "html += \"        </tr>\\n\"\n",
    "\n",
    "for _, row in trend_df.iterrows():\n",
    "    topic_id = row['topic_id']\n",
    "    topic_name = topic_map.get(topic_id, topic_id)\n",
    "    sparkline = row['sparkline']\n",
    "    change_pct = row['7d_change_pct']\n",
    "\n",
    "    change_class = 'positive' if change_pct > 0 else ('negative' if change_pct < 0 else '')\n",
    "    change_str = f\"{change_pct:+.1f}%\"\n",
    "\n",
    "    html += f\"        <tr>\\n\"\n",
    "    html += f\"            <td>{topic_id}</td>\\n\"\n",
    "    html += f\"            <td>{topic_name}</td>\\n\"\n",
    "    html += f\"            <td style='font-family: monospace;'>{sparkline}</td>\\n\"\n",
    "    html += f\"            <td class='{change_class}'>{change_str}</td>\\n\"\n",
    "    html += f\"            <td>{int(row['recent_7d_total'])}</td>\\n\"\n",
    "    html += f\"            <td>{int(row['prev_7d_total'])}</td>\\n\"\n",
    "\n",
    "    for date_str in date_strs[-7:]:\n",
    "        html += f\"            <td>{int(row[date_str])}</td>\\n\"\n",
    "\n",
    "    html += \"        </tr>\\n\"\n",
    "\n",
    "html += \"\"\"\n",
    "    </table>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "html_file = OUTPUT_DIR / f\"topics_trend_{end_date}.html\"\n",
    "html_file.write_text(html)\n",
    "print(f\"‚úì Saved HTML to {html_file}\")\n",
    "\n",
    "# Verify artifacts exist\n",
    "for artifact in [csv_file, html_file, csv_debug_file]:\n",
    "    if not artifact.exists():\n",
    "        raise FileNotFoundError(f\"Missing expected artifact: {artifact}\")\n",
    "\n",
    "print(\"\\nüìä Top 10 Topics (by recent activity):\")\n",
    "latest_col = date_strs[-1]\n",
    "top_topics = trend_df.nlargest(10, latest_col)\n",
    "for _, row in top_topics.iterrows():\n",
    "    topic_id = row['topic_id']\n",
    "    topic_name = topic_map.get(topic_id, topic_id)\n",
    "    count = row[latest_col]\n",
    "    change = row['7d_change_pct']\n",
    "    print(f\"  {topic_name}: {count} reviews ({change:+.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (amazon)",
   "language": "python",
   "name": "amazon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
